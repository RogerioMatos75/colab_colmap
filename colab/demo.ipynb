{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerioMatos75/colab_colmap/blob/main/colab/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiiXJ7K_fePG"
      },
      "source": [
        "<p align=\"center\">\n",
        "    <picture>\n",
        "    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.nerf.studio/_images/logo-dark.png\">\n",
        "    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://docs.nerf.studio/_images/logo.png\">\n",
        "    <img alt=\"nerfstudio\" src=\"https://docs.nerf.studio/_images/logo.png\" width=\"400\">\n",
        "    </picture>\n",
        "</p>\n",
        "\n",
        "\n",
        "# Nerfstudio: A collaboration friendly studio for NeRFs\n",
        "\n",
        "\n",
        "![GitHub stars](https://img.shields.io/github/stars/nerfstudio-project/nerfstudio?color=gold&style=social)\n",
        "\n",
        "This colab shows how to train and view NeRFs from Nerfstudio both on pre-made datasets or from your own videos/images.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Credit to [NeX](https://nex-mpi.github.io/) for Google Colab format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyx5h6kz5ga7"
      },
      "source": [
        "## Frequently Asked Questions\n",
        "\n",
        "*  **Downloading custom data is stalling (no output):**\n",
        "    * This is a bug in Colab. The data is processing, but may take a while to complete. You will know processing completed if `data/nerfstudio/custom_data/transforms.json` exists. Terminating the cell early will result in not being able to train.\n",
        "*  **Processing custom data is taking a long time:**\n",
        "    * The time it takes to process data depends on the number of images and its resolution. If processing is taking too long, try lowering the resolution of your custom data.\n",
        "*  **Error: Data processing did not complete:**\n",
        "    * This means that the data processing script did not fully complete. This could be because there were not enough images, or that the images were of low quality. We recommend images with little to no motion blur and lots of visual overlap of the scene to increase the chances of successful processing.\n",
        "*   **Training is not showing progress**:\n",
        "    * The lack of output is a bug in Colab. You can see the training progress from the viewer.\n",
        "* **Viewer Quality is bad / Low resolution**:\n",
        "    * This may be because more GPU is being used on training that rendering the viewer. Try pausing training or decreasing training utilization.\n",
        "* **WARNING: Running pip as the 'root' user...:**:\n",
        "    * This and other pip warnings or errors can be safely ignored.\n",
        "* **Other problems?**\n",
        "    * Feel free to create an issue on our [GitHub repo](https://github.com/nerfstudio-project/nerfstudio).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oyLHl8QfYwP"
      },
      "outputs": [],
      "source": [
        "# @markdown <h1>Install Nerfstudio and Dependencies (~8 min)</h1>\n",
        "\n",
        "%cd /content/\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Installing PyTorch with CUDA 11.8 support (compatible with Python 3.12)\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Installing COLMAP\n",
        "%cd /content/\n",
        "!apt-get install colmap\n",
        "\n",
        "# Install nerfstudio\n",
        "%cd /content/\n",
        "!pip install git+https://github.com/nerfstudio-project/nerfstudio.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "msVLprI4gRA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "463349ea-5c17-48e5-c477-d68bd91395a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>Select your custom data</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p/>Note: This may take time, especially on higher resolution inputs, so we recommend to download dataset after creation.<p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/nerfstudio/custom_data/raw_images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bfb0562-f16b-49c6-827e-2416c33dc2ef\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4bfb0562-f16b-49c6-827e-2416c33dc2ef\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving frame_0001.png to frame_0001 (3).png\n",
            "Saving frame_0002.png to frame_0002 (3).png\n",
            "Saving frame_0003.png to frame_0003 (3).png\n",
            "Saving frame_0004.png to frame_0004 (3).png\n",
            "Saving frame_0005.png to frame_0005 (3).png\n",
            "Saving frame_0006.png to frame_0006 (3).png\n",
            "Saving frame_0007.png to frame_0007 (3).png\n",
            "Saving frame_0008.png to frame_0008 (3).png\n",
            "Saving frame_0009.png to frame_0009 (3).png\n",
            "Saving frame_0010.png to frame_0010 (3).png\n",
            "Saving frame_0011.png to frame_0011 (3).png\n",
            "Saving frame_0012.png to frame_0012 (3).png\n",
            "Saving frame_0013.png to frame_0013 (3).png\n",
            "Saving frame_0014.png to frame_0014 (3).png\n",
            "Saving frame_0015.png to frame_0015 (3).png\n",
            "Saving frame_0016.png to frame_0016 (3).png\n",
            "Saving frame_0017.png to frame_0017 (3).png\n",
            "Saving frame_0018.png to frame_0018 (3).png\n",
            "Saving frame_0019.png to frame_0019 (3).png\n",
            "Saving frame_0020.png to frame_0020 (3).png\n",
            "Saving frame_0021.png to frame_0021 (3).png\n",
            "Saving frame_0022.png to frame_0022 (3).png\n",
            "Saving frame_0023.png to frame_0023 (3).png\n",
            "Saving frame_0024.png to frame_0024 (3).png\n",
            "Saving frame_0025.png to frame_0025 (3).png\n",
            "Saving frame_0026.png to frame_0026 (3).png\n",
            "Saving frame_0027.png to frame_0027 (3).png\n",
            "Saving frame_0028.png to frame_0028 (3).png\n",
            "Saving frame_0029.png to frame_0029 (3).png\n",
            "Saving frame_0030.png to frame_0030 (3).png\n",
            "Saving frame_0031.png to frame_0031 (3).png\n",
            "Saving frame_0032.png to frame_0032 (3).png\n",
            "Saving frame_0033.png to frame_0033 (3).png\n",
            "Saving frame_0034.png to frame_0034 (3).png\n",
            "Saving frame_0035.png to frame_0035 (3).png\n",
            "Saving frame_0036.png to frame_0036 (3).png\n",
            "Saving frame_0037.png to frame_0037 (3).png\n",
            "Saving frame_0038.png to frame_0038 (3).png\n",
            "Saving frame_0039.png to frame_0039 (3).png\n",
            "Saving frame_0040.png to frame_0040 (3).png\n",
            "Saving frame_0041.png to frame_0041 (3).png\n",
            "Saving frame_0042.png to frame_0042 (3).png\n",
            "Saving frame_0043.png to frame_0043 (3).png\n",
            "Saving frame_0044.png to frame_0044 (3).png\n",
            "Saving frame_0045.png to frame_0045 (3).png\n",
            "Saving frame_0046.png to frame_0046 (3).png\n",
            "Saving frame_0047.png to frame_0047 (3).png\n",
            "Saving frame_0048.png to frame_0048 (3).png\n",
            "Saving frame_0049.png to frame_0049 (3).png\n",
            "Saving frame_0050.png to frame_0050 (3).png\n",
            "Saving frame_0051.png to frame_0051 (3).png\n",
            "Saving frame_0052.png to frame_0052 (3).png\n",
            "Saving frame_0053.png to frame_0053 (3).png\n",
            "Saving frame_0054.png to frame_0054 (3).png\n",
            "Saving frame_0055.png to frame_0055 (3).png\n",
            "Saving frame_0056.png to frame_0056 (3).png\n",
            "Saving frame_0057.png to frame_0057 (3).png\n",
            "Saving frame_0058.png to frame_0058 (3).png\n",
            "Saving frame_0059.png to frame_0059 (3).png\n",
            "Saving frame_0060.png to frame_0060 (3).png\n",
            "Saving frame_0061.png to frame_0061 (3).png\n",
            "Saving frame_0062.png to frame_0062 (3).png\n",
            "Saving frame_0063.png to frame_0063 (3).png\n",
            "Saving frame_0064.png to frame_0064 (3).png\n",
            "Saving frame_0065.png to frame_0065 (3).png\n",
            "Saving frame_0066.png to frame_0066 (3).png\n",
            "Saving frame_0067.png to frame_0067 (3).png\n",
            "Saving frame_0068.png to frame_0068 (3).png\n",
            "Saving frame_0069.png to frame_0069 (3).png\n",
            "Saving frame_0070.png to frame_0070 (3).png\n",
            "Saving frame_0071.png to frame_0071 (3).png\n",
            "Saving frame_0072.png to frame_0072 (3).png\n",
            "Saving frame_0073.png to frame_0073 (3).png\n",
            "Saving frame_0074.png to frame_0074 (3).png\n",
            "Saving frame_0075.png to frame_0075 (3).png\n",
            "Saving frame_0076.png to frame_0076 (3).png\n",
            "Saving frame_0077.png to frame_0077 (3).png\n",
            "Saving frame_0078.png to frame_0078 (3).png\n",
            "Saving frame_0079.png to frame_0079 (3).png\n",
            "Saving frame_0080.png to frame_0080 (3).png\n",
            "Saving frame_0081.png to frame_0081 (3).png\n",
            "Saving frame_0082.png to frame_0082 (3).png\n",
            "Saving frame_0083.png to frame_0083 (3).png\n",
            "Saving frame_0084.png to frame_0084 (3).png\n",
            "Saving frame_0085.png to frame_0085 (3).png\n",
            "Saving frame_0086.png to frame_0086 (3).png\n",
            "Saving frame_0087.png to frame_0087 (3).png\n",
            "Saving frame_0088.png to frame_0088 (3).png\n",
            "Saving frame_0089.png to frame_0089 (3).png\n",
            "Saving frame_0090.png to frame_0090 (3).png\n",
            "Saving frame_0091.png to frame_0091 (3).png\n",
            "Saving frame_0092.png to frame_0092 (3).png\n",
            "Saving frame_0093.png to frame_0093 (3).png\n",
            "Saving frame_0094.png to frame_0094 (3).png\n",
            "Saving frame_0095.png to frame_0095 (3).png\n",
            "Saving frame_0096.png to frame_0096 (3).png\n",
            "Saving frame_0097.png to frame_0097 (3).png\n",
            "Saving frame_0098.png to frame_0098 (3).png\n",
            "Saving frame_0099.png to frame_0099 (3).png\n",
            "Saving frame_0100.png to frame_0100 (3).png\n",
            "Saving frame_0101.png to frame_0101 (3).png\n",
            "Saving frame_0102.png to frame_0102 (3).png\n",
            "Saving frame_0103.png to frame_0103 (3).png\n",
            "Saving frame_0104.png to frame_0104 (3).png\n",
            "Saving frame_0105.png to frame_0105 (3).png\n",
            "Saving frame_0106.png to frame_0106 (3).png\n",
            "Saving frame_0107.png to frame_0107 (3).png\n",
            "Saving frame_0108.png to frame_0108 (3).png\n",
            "Saving frame_0109.png to frame_0109 (3).png\n",
            "Saving frame_0110.png to frame_0110 (3).png\n",
            "Saving frame_0111.png to frame_0111 (3).png\n",
            "Saving frame_0112.png to frame_0112 (3).png\n",
            "Saving frame_0113.png to frame_0113 (3).png\n",
            "Saving frame_0114.png to frame_0114 (3).png\n",
            "Saving frame_0115.png to frame_0115 (3).png\n",
            "Saving frame_0116.png to frame_0116 (3).png\n",
            "Saving frame_0117.png to frame_0117 (3).png\n",
            "Saving frame_0118.png to frame_0118 (3).png\n",
            "Saving frame_0119.png to frame_0119 (3).png\n",
            "Saving frame_0120.png to frame_0120 (3).png\n",
            "Saving frame_0121.png to frame_0121 (3).png\n",
            "Saving frame_0122.png to frame_0122 (3).png\n",
            "Saving frame_0123.png to frame_0123 (3).png\n",
            "Saving frame_0124.png to frame_0124 (3).png\n",
            "Saving frame_0125.png to frame_0125 (3).png\n",
            "Saving frame_0126.png to frame_0126 (3).png\n",
            "Saving frame_0127.png to frame_0127 (3).png\n",
            "Saving frame_0128.png to frame_0128 (3).png\n",
            "Saving frame_0129.png to frame_0129 (3).png\n",
            "Saving frame_0130.png to frame_0130 (3).png\n",
            "Saving frame_0131.png to frame_0131 (3).png\n",
            "Saving frame_0132.png to frame_0132 (3).png\n",
            "Saving frame_0133.png to frame_0133 (3).png\n",
            "Saving frame_0134.png to frame_0134 (3).png\n",
            "Saving frame_0135.png to frame_0135 (3).png\n",
            "Saving frame_0136.png to frame_0136 (3).png\n",
            "Saving frame_0137.png to frame_0137 (3).png\n",
            "Saving frame_0138.png to frame_0138 (3).png\n",
            "Saving frame_0139.png to frame_0139 (3).png\n",
            "Saving frame_0140.png to frame_0140 (3).png\n",
            "Saving frame_0141.png to frame_0141 (3).png\n",
            "Saving frame_0142.png to frame_0142 (3).png\n",
            "Saving frame_0143.png to frame_0143 (3).png\n",
            "Saving frame_0144.png to frame_0144 (3).png\n",
            "Saving frame_0145.png to frame_0145 (3).png\n",
            "Saving frame_0146.png to frame_0146 (3).png\n",
            "Saving frame_0147.png to frame_0147 (3).png\n",
            "Saving frame_0148.png to frame_0148 (3).png\n",
            "Saving frame_0149.png to frame_0149 (3).png\n",
            "Saving frame_0150.png to frame_0150 (3).png\n",
            "Saving frame_0151.png to frame_0151 (3).png\n",
            "Saving frame_0152.png to frame_0152 (3).png\n",
            "Saving frame_0153.png to frame_0153 (3).png\n",
            "Saving frame_0154.png to frame_0154 (3).png\n",
            "Saving frame_0155.png to frame_0155 (3).png\n",
            "Saving frame_0156.png to frame_0156 (3).png\n",
            "Saving frame_0157.png to frame_0157 (3).png\n",
            "Saving frame_0158.png to frame_0158 (3).png\n",
            "Saving frame_0159.png to frame_0159 (3).png\n",
            "Saving frame_0160.png to frame_0160 (3).png\n",
            "Saving frame_0161.png to frame_0161 (3).png\n",
            "Saving frame_0162.png to frame_0162 (3).png\n",
            "Saving frame_0163.png to frame_0163 (3).png\n",
            "Saving frame_0164.png to frame_0164 (3).png\n",
            "Saving frame_0165.png to frame_0165 (3).png\n",
            "Saving frame_0166.png to frame_0166 (3).png\n",
            "Saving frame_0167.png to frame_0167 (3).png\n",
            "Saving frame_0168.png to frame_0168 (3).png\n",
            "Saving frame_0169.png to frame_0169 (3).png\n",
            "Saving frame_0170.png to frame_0170 (3).png\n",
            "Saving frame_0171.png to frame_0171 (3).png\n",
            "Saving frame_0172.png to frame_0172 (3).png\n",
            "Saving frame_0173.png to frame_0173 (3).png\n",
            "Saving frame_0174.png to frame_0174 (3).png\n",
            "Saving frame_0175.png to frame_0175 (3).png\n",
            "Saving frame_0176.png to frame_0176 (3).png\n",
            "Saving frame_0177.png to frame_0177 (3).png\n",
            "Saving frame_0178.png to frame_0178 (3).png\n",
            "Saving frame_0179.png to frame_0179 (3).png\n",
            "Saving frame_0180.png to frame_0180 (3).png\n",
            "Saving frame_0181.png to frame_0181 (3).png\n",
            "Saving frame_0182.png to frame_0182 (3).png\n",
            "Saving frame_0183.png to frame_0183 (3).png\n",
            "Saving frame_0184.png to frame_0184 (3).png\n",
            "Saving frame_0185.png to frame_0185 (3).png\n",
            "Saving frame_0186.png to frame_0186 (3).png\n",
            "Saving frame_0187.png to frame_0187 (3).png\n",
            "/content\n",
            "\u001b[91m╭─\u001b[0m\u001b[91m \u001b[0m\u001b[1;91mUnrecognized options\u001b[0m\u001b[91m \u001b[0m\u001b[91m──────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n",
            "\u001b[91m│\u001b[0m Unrecognized options: --ImageReader.camera-model \u001b[91m│\u001b[0m\n",
            "\u001b[91m│\u001b[0m \u001b[31m────────────────────────────────────────────────\u001b[0m \u001b[91m│\u001b[0m\n",
            "\u001b[91m│\u001b[0m For full helptext, run \u001b[1mns-process-data --help\u001b[0m    \u001b[91m│\u001b[0m\n",
            "\u001b[91m╰──────────────────────────────────────────────────╯\u001b[0m\n",
            "Data Processing Succeeded!\n"
          ]
        }
      ],
      "source": [
        "# @markdown <h1> Downloading and Processing Data</h1>\n",
        "# @markdown <h3>Pick the preset scene or upload your own images/video</h3>\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.core.display import HTML, display\n",
        "\n",
        "scene = \"📤 upload your images\"  # @param ['🖼 poster', '🚜 dozer', '🌄 desolation', '📤 upload your images' , '🎥 upload your own video', '🔺 upload Polycam data', '💽 upload your own Record3D data']\n",
        "scene = \" \".join(scene.split(\" \")[1:])\n",
        "\n",
        "if scene == \"upload Polycam data\":\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    if len(uploaded.keys()) > 1:\n",
        "        print(\"ERROR, upload a single .zip file when processing Polycam data\")\n",
        "    dataset_dir = [os.path.join(dir, f) for f in uploaded.keys()][0]\n",
        "    !ns-process-data polycam --data $dataset_dir --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene == \"upload your own Record3D data\":\n",
        "    display(HTML(\"<h3>Zip your Record3D folder, and upload.</h3>\"))\n",
        "    display(\n",
        "        HTML(\n",
        "            '<h3>More information on Record3D can be found <a href=\"https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#record3d-capture\" target=\"_blank\">here</a>.</h3>'\n",
        "        )\n",
        "    )\n",
        "    %cd /content/\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    %cd /content/data/nerfstudio/custom_data/\n",
        "    uploaded = files.upload()\n",
        "    dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    record_3d_zipfile = preupload_datasets[0]\n",
        "    !unzip $record_3d_zipfile -d /content/data/nerfstudio/custom_data\n",
        "    custom_data_directory = glob.glob(\"/content/data/nerfstudio/custom_data/*\")[0]\n",
        "    !ns-process-data record3d --data $custom_data_directory --output-dir /content/data/nerfstudio/custom_data/\n",
        "    scene = \"custom_data\"\n",
        "elif scene in [\"upload your images\", \"upload your own video\"]:\n",
        "    display(HTML(\"<h3>Select your custom data</h3>\"))\n",
        "    display(HTML(\"<p/>You can select multiple images by pressing ctrl, cmd or shift and click.<p>\"))\n",
        "    display(\n",
        "        HTML(\n",
        "            \"<p/>Note: This may take time, especially on higher resolution inputs, so we recommend to download dataset after creation.<p>\"\n",
        "        )\n",
        "    )\n",
        "    !mkdir -p /content/data/nerfstudio/custom_data\n",
        "    if scene == \"upload your images\":\n",
        "        !mkdir -p /content/data/nerfstudio/custom_data/raw_images\n",
        "        %cd /content/data/nerfstudio/custom_data/raw_images\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    else:\n",
        "        %cd /content/data/nerfstudio/custom_data/\n",
        "        uploaded = files.upload()\n",
        "        dir = os.getcwd()\n",
        "    preupload_datasets = [os.path.join(dir, f) for f in uploaded.keys()]\n",
        "    del uploaded\n",
        "    %cd /content/\n",
        "\n",
        "    if scene == \"upload your images\":\n",
        "        !ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/ --ImageReader.camera_model SIMPLE_RADIAL\n",
        "    else:\n",
        "        video_path = preupload_datasets[0]\n",
        "        !ns-process-data video --data $video_path --output-dir /content/data/nerfstudio/custom_data/ --ImageReader.camera_model SIMPLE_RADIAL\n",
        "\n",
        "    scene = \"custom_data\"\n",
        "else:\n",
        "    %cd /content/\n",
        "    !ns-download-data nerfstudio --capture-name=$scene\n",
        "\n",
        "print(\"Data Processing Succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "m_N8_cLfjoXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "af0de63a-2d3a-4b4d-f000-7e4db31825b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3 style=\"color:red\">Error: Data processing did not complete</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>Please re-run `Downloading and Processing Data`, or view the FAQ for more info.</h3>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown <h1>Start Training</h1>\n",
        "\n",
        "%cd /content\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%env TERM=xterm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output(wait=True)\n",
        "if os.path.exists(f\"data/nerfstudio/{scene}/transforms.json\"):\n",
        "    print(\n",
        "        \"\\033[1m\"\n",
        "        + \"Copy and paste the following command into the terminal window that pops up under this cell.\"\n",
        "        + \"\\033[0m\"\n",
        "    )\n",
        "    print(\n",
        "        f\"ns-train nerfacto --viewer.websocket-port 7007 --viewer.make-share-url True nerfstudio-data --data data/nerfstudio/{scene} --downscale-factor 4\"\n",
        "    )\n",
        "    print()\n",
        "    %xterm\n",
        "else:\n",
        "    from IPython.core.display import HTML, display\n",
        "\n",
        "    display(HTML('<h3 style=\"color:red\">Error: Data processing did not complete</h3>'))\n",
        "    display(HTML(\"<h3>Please re-run `Downloading and Processing Data`, or view the FAQ for more info.</h3>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGt8ukG6Htg3"
      },
      "outputs": [],
      "source": [
        "# @title # Render Video { vertical-output: true }\n",
        "# @markdown <h3>Export the camera path from within the viewer, then run this cell.</h3>\n",
        "# @markdown <h5>The rendered video should be at renders/output.mp4!</h5>\n",
        "\n",
        "\n",
        "base_dir = \"/content/outputs/unnamed/nerfacto/\"\n",
        "training_run_dir = base_dir + os.listdir(base_dir)[0]\n",
        "\n",
        "from IPython.core.display import HTML, display\n",
        "\n",
        "display(HTML(\"<h3>Upload the camera path JSON.</h3>\"))\n",
        "%cd $training_run_dir\n",
        "uploaded = files.upload()\n",
        "uploaded_camera_path_filename = list(uploaded.keys())[0]\n",
        "\n",
        "config_filename = training_run_dir + \"/config.yml\"\n",
        "camera_path_filename = training_run_dir + \"/\" + uploaded_camera_path_filename\n",
        "camera_path_filename = camera_path_filename.replace(\" \", \"\\\\ \").replace(\"(\", \"\\\\(\").replace(\")\", \"\\\\)\")\n",
        "\n",
        "%cd /content/\n",
        "!ns-render camera-path --load-config $config_filename --camera-path-filename $camera_path_filename --output-path renders/output.mp4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/"
      ],
      "metadata": {
        "id": "5d3Nck2WejzQ",
        "outputId": "439a3b12-de40-48ca-c7e7-33aea25c79ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\u001b[2;36m[20:47:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32m🎉 Done copying images with prefix \u001b[0m\u001b[1;32m'frame_'\u001b[0m\u001b[1;32m.\u001b[0m                                        \u001b]8;id=376812;file:///usr/local/lib/python3.12/dist-packages/nerfstudio/process_data/process_data_utils.py\u001b\\\u001b[2mprocess_data_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=850321;file:///usr/local/lib/python3.12/dist-packages/nerfstudio/process_data/process_data_utils.py#348\u001b\\\u001b[2m348\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2K\u001b[32m(    ● )\u001b[0m \u001b[1;33mCopying images...\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[?25l\u001b[31m────────────────────────────────────────────── \u001b[0m\u001b[1;31m 💀 💀 💀 ERROR 💀 💀 💀 \u001b[0m\u001b[31m ───────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[1;31mError running command: colmap feature_extractor --database_path \u001b[0m\u001b[1;31m/content/data/nerfstudio/custom_data/colmap/\u001b[0m\u001b[1;31mdatabase.db\u001b[0m\u001b[1;31m \u001b[0m\n",
            "\u001b[1;31m--image_path \u001b[0m\u001b[1;31m/content/data/nerfstudio/custom_data/\u001b[0m\u001b[1;31mimages\u001b[0m\u001b[1;31m --ImageReader.single_camera \u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m --ImageReader.camera_model OPENCV\u001b[0m\n",
            "\u001b[1;31m--SiftExtraction.use_gpu \u001b[0m\u001b[1;31m1\u001b[0m\n",
            "\u001b[2K\u001b[31m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2Kqt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \u001b[32m\"xcb\"\u001b[0m in \u001b[32m\"\"\u001b[0m even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may \n",
            "fix this problem.\n",
            "\n",
            "Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, xcb.\n",
            "\n",
            "*** Aborted at \u001b[1;36m1758746863\u001b[0m \u001b[1m(\u001b[0munix time\u001b[1m)\u001b[0m try \u001b[32m\"date -d @1758746863\"\u001b[0m if you are using GNU date ***\n",
            "PC: @                \u001b[1;36m0x0\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "*** SIGABRT \u001b[1m(\u001b[0m@\u001b[1;36m0x10c2e\u001b[0m\u001b[1m)\u001b[0m received by PID \u001b[1;36m68654\u001b[0m \u001b[1m(\u001b[0mTID \u001b[1;36m0x7b5891f77080\u001b[0m\u001b[1m)\u001b[0m from PID \u001b[1;36m68654\u001b[0m; stack trace: ***\n",
            "    @     \u001b[1;36m0x7b589a52b046\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b589859e520\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b58985f29fc\u001b[0m pthread_kill\n",
            "    @     \u001b[1;36m0x7b589859e476\u001b[0m raise\n",
            "    @     \u001b[1;36m0x7b58985847f3\u001b[0m abort\n",
            "    @     \u001b[1;36m0x7b5898b92ba3\u001b[0m QMessageLogger::\u001b[1;35mfatal\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b5899199713\u001b[0m QGuiApplicationPrivat\u001b[1;92me::c\u001b[0m\u001b[1;35mreatePlatformIntegration\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b5899199c08\u001b[0m QGuiApplicationPrivat\u001b[1;92me::c\u001b[0m\u001b[1;35mreateEventDispatcher\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b5898dc2b17\u001b[0m QCoreApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b589919cb70\u001b[0m QGuiApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b58998b0ced\u001b[0m QApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x555a5d7f93dd\u001b[0m colmap::\u001b[1;35mRunFeatureExtractor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x555a5d7eb499\u001b[0m main\n",
            "    @     \u001b[1;36m0x7b5898585d90\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7b5898585e40\u001b[0m __libc_start_main\n",
            "    @     \u001b[1;36m0x555a5d7ee3e5\u001b[0m _start\n",
            "Aborted \u001b[1m(\u001b[0mcore dumped\u001b[1m)\u001b[0m\n",
            "\n",
            "\u001b[2K\u001b[32m🌑 \u001b[0m \u001b[1;33mRunning COLMAP feature extractor...\u001b[0m\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/"
      ],
      "metadata": {
        "id": "D_4tVOe3fZGJ",
        "outputId": "d4f6bbbf-0373-4dd2-b4d7-57d7bf641666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\u001b[2;36m[20:51:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32m🎉 Done copying images with prefix \u001b[0m\u001b[1;32m'frame_'\u001b[0m\u001b[1;32m.\u001b[0m                                        \u001b]8;id=222022;file:///usr/local/lib/python3.12/dist-packages/nerfstudio/process_data/process_data_utils.py\u001b\\\u001b[2mprocess_data_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=503960;file:///usr/local/lib/python3.12/dist-packages/nerfstudio/process_data/process_data_utils.py#348\u001b\\\u001b[2m348\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2K\u001b[32m(    ● )\u001b[0m \u001b[1;33mCopying images...\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[?25l\u001b[31m────────────────────────────────────────────── \u001b[0m\u001b[1;31m 💀 💀 💀 ERROR 💀 💀 💀 \u001b[0m\u001b[31m ───────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[1;31mError running command: colmap feature_extractor --database_path \u001b[0m\u001b[1;31m/content/data/nerfstudio/custom_data/colmap/\u001b[0m\u001b[1;31mdatabase.db\u001b[0m\u001b[1;31m \u001b[0m\n",
            "\u001b[1;31m--image_path \u001b[0m\u001b[1;31m/content/data/nerfstudio/custom_data/\u001b[0m\u001b[1;31mimages\u001b[0m\u001b[1;31m --ImageReader.single_camera \u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m --ImageReader.camera_model OPENCV\u001b[0m\n",
            "\u001b[1;31m--SiftExtraction.use_gpu \u001b[0m\u001b[1;31m1\u001b[0m\n",
            "\u001b[2K\u001b[31m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2Kqt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \u001b[32m\"xcb\"\u001b[0m in \u001b[32m\"\"\u001b[0m even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may \n",
            "fix this problem.\n",
            "\n",
            "Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, xcb.\n",
            "\n",
            "*** Aborted at \u001b[1;36m1758747072\u001b[0m \u001b[1m(\u001b[0munix time\u001b[1m)\u001b[0m try \u001b[32m\"date -d @1758747072\"\u001b[0m if you are using GNU date ***\n",
            "PC: @                \u001b[1;36m0x0\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "*** SIGABRT \u001b[1m(\u001b[0m@\u001b[1;36m0x10fcd\u001b[0m\u001b[1m)\u001b[0m received by PID \u001b[1;36m69581\u001b[0m \u001b[1m(\u001b[0mTID \u001b[1;36m0x7806a7383080\u001b[0m\u001b[1m)\u001b[0m from PID \u001b[1;36m69581\u001b[0m; stack trace: ***\n",
            "    @     \u001b[1;36m0x7806af937046\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ad9be520\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ada129fc\u001b[0m pthread_kill\n",
            "    @     \u001b[1;36m0x7806ad9be476\u001b[0m raise\n",
            "    @     \u001b[1;36m0x7806ad9a47f3\u001b[0m abort\n",
            "    @     \u001b[1;36m0x7806adf92ba3\u001b[0m QMessageLogger::\u001b[1;35mfatal\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ae599713\u001b[0m QGuiApplicationPrivat\u001b[1;92me::c\u001b[0m\u001b[1;35mreatePlatformIntegration\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ae599c08\u001b[0m QGuiApplicationPrivat\u001b[1;92me::c\u001b[0m\u001b[1;35mreateEventDispatcher\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ae1c2b17\u001b[0m QCoreApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ae59cb70\u001b[0m QGuiApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806aecb0ced\u001b[0m QApplicationPrivate::\u001b[1;35minit\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x57f66fdb03dd\u001b[0m colmap::\u001b[1;35mRunFeatureExtractor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x57f66fda2499\u001b[0m main\n",
            "    @     \u001b[1;36m0x7806ad9a5d90\u001b[0m \u001b[1m(\u001b[0munknown\u001b[1m)\u001b[0m\n",
            "    @     \u001b[1;36m0x7806ad9a5e40\u001b[0m __libc_start_main\n",
            "    @     \u001b[1;36m0x57f66fda53e5\u001b[0m _start\n",
            "Aborted \u001b[1m(\u001b[0mcore dumped\u001b[1m)\u001b[0m\n",
            "\n",
            "\u001b[2K\u001b[32m🌑 \u001b[0m \u001b[1;33mRunning COLMAP feature extractor...\u001b[0m\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('nerfstudio')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}